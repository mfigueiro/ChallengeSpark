### CODE IN R ###

####### load packages ######
packageVersion("sparklyr") ## new version
library(sparklyr)
library(data.table)
library(dplyr)
library(tidyverse)

####### Connect to local Spark instance #######
#spark_available_versions()
#spark_install("2.4.3")
#spark_installed_versions()
sc <- spark_connect(master = "local", 
                    spark_home= Sys.getenv("SPARK_HOME"),
                    version = "2.4.3")
spark_web(sc)

####### read the dataset into R #######
ks_tbl <- read.csv("data1.csv",sep=',', quote= "",
                fill=TRUE,
                header=TRUE, stringsAsFactors=FALSE)
names(ks_tbl)[13]<-paste("usd.pledged")

# basic check to see the data has been properly read
str(ks_tbl)
names(ks_tbl)
head(ks_tbl)
dim(ks_tbl) ### 13 variables
class(ks_tbl)
View(ks_tbl)

####### Data preprocessing ######
# concatenate names when they contain a comma
dat$name <- ifelse(nchar(dat$category)>0,
                   dat$name <- paste(dat$name,dat$category,
                                     sep=','),
                   for (i in 3:13) 
                     colnames(dat)[i] <- colnames(dat)[i+1]
)


# pushing the data into Spark DataFrame
ks_proj_tbl <- copy_to(sc, ks_tbl, "ks_projects", overwrite = TRUE)


# check if the table is available on Spark
src_tbls(sc)


### data analysis and save the results 
ks_tbl %>% dplyr::select(ID,category,country)
res0 <- table(ks_tbl$country) 
capture.output(res0,file = "file.csv")  ### save the results

spark_disconnect(sc)
